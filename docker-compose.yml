services:
  namenode:
    image: leonardodavinci03/hadoop
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./hadoop_image/hadoop.env
    environment:
      ENSURE_NAMENODE_DIR: "/opt/hadoop/dfs/name"
      HADOOP_HOME: "/opt/hadoop" 
    volumes:
      - hadoop_namenode:/opt/hadoop/dfs/name
      - ./spark_jars:/opt/hadoop/dfs/spark/jars
  datanode:
    image: leonardodavinci03/hadoop
    command: ["hdfs", "datanode"]
    env_file:
      - ./hadoop_image/hadoop.env
    environment:
      HADOOP_HOME: "/opt/hadoop" 
    depends_on:
      - namenode
    volumes:
      - hadoop_datanode:/opt/hadoop/dfs/data

  resourcemanager:
    image: leonardodavinci03/hadoop
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
      - 8088:8088
    depends_on:
      - namenode
      - datanode
    env_file:
      - ./hadoop_image/hadoop.env
    environment:
      HADOOP_HOME: "/opt/hadoop"

  nodemanager:
    image: leonardodavinci03/hadoop
    command: ["yarn", "nodemanager"]
    ports:
      - 8042:8042
    depends_on:
      - namenode
      - datanode
      - resourcemanager
    env_file:
      - ./hadoop_image/hadoop.env
    environment:
      HADOOP_HOME: "/opt/hadoop"

  spark-master:
    image: leonardodavinci03/spark-master
    hostname: spark-master
    ports:
      - "4040:4040"
      - "4041:4041"
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    entrypoint: 
      - "bash"
      - "-c"
      - "/opt/spark/sbin/start-master.sh && tail -f /dev/null"
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
      - ./jars:/opt/spark/extra_jars
      - ./conf:/opt/spark/conf
      - ./hadoop:/opt/hadoop

  spark-connect:
    image: leonardodavinci03/spark-master
    hostname: spark-connect
    ports:
      - "15002:15002"
    depends_on:
      - spark-master
    command: 
      - "bash"
      - "-c"
      - "/opt/spark/sbin/start-connect-server.sh && tail -f /dev/null"
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf

  spark-worker:
    image: leonardodavinci03/spark-master
    hostname: spark-worker
    depends_on:
      - spark-master
    entrypoint:
      - "bash" 
      - "-c"
      - "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf

  zookeep1:
    image: zookeeper:3.4.14
    hostname: zookeep1
    ports:
      - "2181:2181"
    environment:
        ZOO_MY_ID: 1
        ZOO_PORT: 2181
        ZOO_SERVERS: server.1=zookeep1:2888:3888
    volumes:
      - zookeeper1_data:/data
      - zookeeper1_datalog:/datalog

  kafka1:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeep1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    volumes:
      - kafka1_data:/var/lib/kafka/data
    depends_on:
      - zookeep1
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s

  cassandra:
    image: cassandra:latest
    hostname: cassandra1
    ports:
      - "9042:9042"
    volumes:
      - cassandra_data:/var/lib/cassandra
    environment:
      - CASSANDRA_CLUSTER_NAME=MyCluster

  prometheus:
    image: prom/prometheus
    hostname: prometheus1
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana-storage:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus

  loki:
    image: grafana/loki:latest
    ports:
      - "3100:3100"

volumes:
  hadoop_namenode:
  hadoop_datanode:
  cassandra_data:
  kafka1_data:
  zookeeper1_data:
  zookeeper1_datalog:
  grafana-storage:
